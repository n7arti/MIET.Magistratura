{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh1P041u7XRJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Удаление пунктуации\n",
        "    text = text.lower()  # Приведение к нижнему регистру\n",
        "    return text"
      ],
      "metadata": {
        "id": "cLAnbgw1CAlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"vfomenko/russian-news-2020\")\n",
        "file_path = f\"{path}/news.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAVQYiBf7fZK",
        "outputId": "6c4a07e4-338b-49bd-c0f7-781cd7739010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vfomenko/russian-news-2020?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.9M/19.9M [00:00<00:00, 81.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     source                                           title  \\\n",
            "0  lenta.ru                                  Синий богатырь   \n",
            "1  lenta.ru  Загитова согласилась вести «Ледниковый период»   \n",
            "2  lenta.ru       Объяснена опасность однообразного питания   \n",
            "3  lenta.ru                      «Предохраняться? А зачем?»   \n",
            "4  lenta.ru     Ефремов систематически употреблял наркотики   \n",
            "\n",
            "                                                text  \\\n",
            "0  В 1930-е годы Советский Союз охватила лихорадк...   \n",
            "1  Олимпийская чемпионка по фигурному катанию  Ал...   \n",
            "2  Российский врач-диетолог Римма Мойсенко объясн...   \n",
            "3  В 2019 году телеканал «Ю» запустил адаптацию з...   \n",
            "4  Актер  Михаил Ефремов  систематически употребл...   \n",
            "\n",
            "            publication_date          rubric     subrubric tags  \n",
            "0  2020-08-30T00:01:00+03:00       Экономика  Госэкономика  NaN  \n",
            "1  2020-08-31T20:04:00+03:00           Спорт   Зимние виды  NaN  \n",
            "2  2020-08-31T20:07:00+03:00        Из жизни           Еда  NaN  \n",
            "3  2020-08-30T00:04:00+03:00  Интернет и СМИ    ТВ и радио  NaN  \n",
            "4  2020-08-31T18:27:00+03:00        Культура          Кино  NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря символов\n",
        "data['text'] = data['text'].fillna(\"\")\n",
        "data['text'] = data['text'].apply(clean_text)\n",
        "\n",
        "# Создание словаря слов\n",
        "words = \" \".join(data['text']).split()\n",
        "word_to_index = {word: i for i, word in enumerate(set(words))}\n",
        "index_to_word = {i: word for i, word in enumerate(set(words))}\n",
        "\n",
        "# Преобразование текста в последовательности слов\n",
        "max_sequence_length = 10  # Максимальная длина последовательности\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for text in data['text']:\n",
        "    tokens = text.split()\n",
        "    for i in range(len(tokens) - 1):\n",
        "        input_seq = tokens[:i + 1]\n",
        "        target_word = tokens[i + 1]\n",
        "        X.append([word_to_index[word] for word in input_seq])\n",
        "        y.append(word_to_index[target_word])\n",
        "\n",
        "# Дополнение последовательностей до одинаковой длины\n",
        "X = pad_sequences(X, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Преобразование целевых значений в one-hot encoding\n",
        "y = to_categorical(y, num_classes=len(word_to_index))"
      ],
      "metadata": {
        "id": "nq0fVaaL7vya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"demartlectus/wildberries-search-queries-from-wildhack-2021\")\n",
        "file_path = f\"{path}/query_popularity.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffae713c-af34-4c3c-d0cc-35c7cec2d29c",
        "id": "7rdRlVw4EipD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    query  query_popularity\n",
            "0                 ноутбук                10\n",
            "1  куртка женская осенняя                10\n",
            "2         ботинки женские                10\n",
            "3              видеокарта                10\n",
            "4  пальто женское осеннее                10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря символов\n",
        "data['query'] = data['query'].fillna(\"\")\n",
        "data['query'] = data['query'].apply(clean_text)\n",
        "\n",
        "# Создание словаря слов\n",
        "words = \" \".join(data['query']).split()\n",
        "word_to_index = {word: i for i, word in enumerate(set(words))}\n",
        "index_to_word = {i: word for i, word in enumerate(set(words))}\n",
        "\n",
        "# Преобразование текста в последовательности слов\n",
        "max_sequence_length = 10  # Максимальная длина последовательности\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for text in data['query']:\n",
        "    tokens = text.split()\n",
        "    for i in range(len(tokens) - 1):\n",
        "        input_seq = tokens[:i + 1]\n",
        "        target_word = tokens[i + 1]\n",
        "        X.append([word_to_index[word] for word in input_seq])\n",
        "        y.append(word_to_index[target_word])\n",
        "\n",
        "# Дополнение последовательностей до одинаковой длины\n",
        "X = pad_sequences(X, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "# Преобразование целевых значений в one-hot encoding\n",
        "y = to_categorical(y, num_classes=len(word_to_index))"
      ],
      "metadata": {
        "id": "-BwTDS9bEvET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "embedding_dim = 50\n",
        "lstm_units = 128\n",
        "\n",
        "# Создание модели\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(words), output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "    LSTM(lstm_units),\n",
        "    Dense(len(words), activation='softmax')\n",
        "])\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit(X, y, epochs=50, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "jQOw0XjL_LPO",
        "outputId": "dcd72c30-f26c-4a08-f45e-29e0db1c8169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Sequential' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e03ad6171b24>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Создание модели\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m model = Sequential([\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации текста\n",
        "def generate_text(seed_text, num_chars_to_generate, temperature=1.0):\n",
        "    for _ in range(num_chars_to_generate):\n",
        "        # Преобразование seed_text в последовательность индексов\n",
        "        input_seq = [char_to_index[char] for char in seed_text]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "        # Предсказание вероятностей следующего символа\n",
        "        predicted_probs = model.predict(input_seq, verbose=0)[0]\n",
        "\n",
        "        # Применение температуры для \"смягчения\" вероятностей\n",
        "        predicted_probs = np.log(predicted_probs) / temperature\n",
        "        predicted_probs = np.exp(predicted_probs)\n",
        "        predicted_probs = predicted_probs / np.sum(predicted_probs)\n",
        "\n",
        "        # Случайный выбор символа на основе вероятностей\n",
        "        predicted_index = np.random.choice(len(chars), p=predicted_probs)\n",
        "        predicted_char = index_to_char[predicted_index]\n",
        "\n",
        "        # Добавление предсказанного символа к seed_text\n",
        "        seed_text += predicted_char\n",
        "\n",
        "    return seed_text\n",
        "\n",
        "# Генерация текста\n",
        "seed_texts = [\"шуба\", \"акриловые\", \"я\"]\n",
        "for seed in seed_texts:\n",
        "    generated_text = generate_text(seed, num_chars_to_generate=50)\n",
        "    print(f\"Начальная фраза: '{seed}'\")\n",
        "    print(f\"Сгенерированный текст: {generated_text}\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpc9uONg_gEJ",
        "outputId": "70c00cf2-1680-4578-a4e2-68c7cd0a4596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начальная фраза: 'шуба'\n",
            "Сгенерированный текст: шубаictooubucebcleitrinbbiluouarirtoibbuucuounibsa_ece\n",
            "--------------------------------------------------\n",
            "Начальная фраза: 'акриловые'\n",
            "Сгенерированный текст: акриловыеtiiilabarcrctucucuauluiuiciittxcgcuuuaioelrtcnedao\n",
            "--------------------------------------------------\n",
            "Начальная фраза: 'я'\n",
            "Сгенерированный текст: яr_buioairenebnbetbcliebaabiucclicictablrrurrbeаbtt\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}