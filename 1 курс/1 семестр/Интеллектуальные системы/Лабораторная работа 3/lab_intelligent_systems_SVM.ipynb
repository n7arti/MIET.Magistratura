{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1546e246",
      "metadata": {
        "id": "1546e246"
      },
      "source": [
        "# Лабораторная работа 3\n",
        "*********\n",
        "## Статистические методы обучения. Метод опорных векторов"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На этом занятии компьютерного практикума Вы изучите метод опорных векторов (англ. SVM, Support Vector Machine) и примените данный метод для решения задачи классификации различных двумерных наборов данных. В последних публикациях на русском языке метод называется также машинами поддерживающих векторов, или, в более общем смысле, ядерными машинами (англ. Kernel Machine). В методах, основанных на их использовании, предусмотрен эффективный механизм обучения, а сами они позволяют представить сложные, нелинейные функции.   \n",
        "\n",
        "Ядерные машины превосходят все другие способы распознавания рукописных символов, в частности цифр; кроме того, они быстро находят применение и в других приложениях, особенно в тех, которые отличаются большим количеством входных характеристик. Прежде чем приступить, собственно, к программированию, настоятельно рекомендуется ознакомиться с материалом лекций, а также с дополнительными материалами, имеющими отношение к задачам классификации.\n"
      ],
      "metadata": {
        "id": "Mmh7zolZWAKB"
      },
      "id": "Mmh7zolZWAKB"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4c9ba171",
      "metadata": {
        "id": "4c9ba171"
      },
      "outputs": [],
      "source": [
        "# импортирую все необходимые библиотеки\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from matplotlib import cm\n",
        "from matplotlib import pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "from sklearn import svm\n",
        "import scipy.io"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57c7453c",
      "metadata": {
        "id": "57c7453c"
      },
      "source": [
        "## Часть 1: Загрузка и визуализация данных"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как было сказано выше, Вы будете использовать метод опорных векторов для классификации 2-мерных наборов данных. В ходе работы над упражнением вы изучите собственно метод, а также научитесь использовать с SVM ядро Гаусса."
      ],
      "metadata": {
        "id": "oD0TOV_yY1hU"
      },
      "id": "oD0TOV_yY1hU"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6cd749c8",
      "metadata": {
        "id": "6cd749c8"
      },
      "outputs": [],
      "source": [
        "mat = scipy.io.loadmat('ex3data1.mat')\n",
        "X = mat[\"X\"]\n",
        "y = mat[\"y\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "94e8d75a",
      "metadata": {
        "id": "94e8d75a"
      },
      "outputs": [],
      "source": [
        "def plotData(X, y):\n",
        "  # ====================== Ваш код здесь ======================\n",
        "  # Указание: Реализуйте функцию, которая будет визуализировать набор данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a98b9b2",
      "metadata": {
        "id": "9a98b9b2"
      },
      "outputs": [],
      "source": [
        "plotData(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f52007e",
      "metadata": {
        "id": "5f52007e"
      },
      "source": [
        "## Часть 2: Обучение линейного классификатора SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c71d4ab5",
      "metadata": {
        "id": "c71d4ab5"
      },
      "outputs": [],
      "source": [
        "def svmTrain(X, y, C, kernelFunction, tol=1e-3, max_passes=-1, sigma=0.1):\n",
        "    y = y.flatten()\n",
        "\n",
        "    if kernelFunction == \"gaussian_rbf\":\n",
        "        clf = svm.SVC(C = C, kernel=\"rbf\", tol=tol, max_iter=max_passes, verbose=2)\n",
        "        return clf.fit(gaussianKernelGramMatrix(X,X, sigma=sigma), y)\n",
        "\n",
        "    else:\n",
        "        clf = svm.SVC(C = C, kernel=kernelFunction, tol=tol, max_iter=max_passes, verbose=2)\n",
        "        return clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c634401a",
      "metadata": {
        "id": "c634401a"
      },
      "outputs": [],
      "source": [
        "def visualizeBoundaryLinear(X, y, model, c):\n",
        "    plotData(X, y)\n",
        "    w = model.coef_[0]\n",
        "    b = model.intercept_[0]\n",
        "    xp = np.linspace(X[:,0].min(), X[:,0].max(), 100)\n",
        "    yp = - (w[0] * xp + b) / w[1]\n",
        "\n",
        "    plt.plot(xp, yp, linewidth = 3, color = 'blue', label='Граница классов')\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.title('\\n C = {:d} \\n'.format(c), fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0569fac6",
      "metadata": {
        "scrolled": false,
        "id": "0569fac6"
      },
      "outputs": [],
      "source": [
        "# Ваша задача в этой ячейке проанализировать как влияет параметр С на качество классификаци.\n",
        "# Получить графики как на рисунках 2,3 и написать вывод.\n",
        "C = [1, 100, 1000]\n",
        "for c in C:\n",
        "    model = svmTrain(X, y, c, \"linear\", 1e-3, 20)\n",
        "    visualizeBoundaryLinear(X, y, model, c)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "523cddb3",
      "metadata": {
        "id": "523cddb3"
      },
      "source": [
        "## Часть 3: Применение радиальной базисной функции (ядра) Гаусса"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой части упражнения демонстрируется применение метода опорных векторов для нелинейной классификации данных. В частности, предстоит применить SVM с ядром Гаусса в ситуации, когда линейное разделение невозможно."
      ],
      "metadata": {
        "id": "nC6bFnoLinYu"
      },
      "id": "nC6bFnoLinYu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для нахождения нелинейных границ с помощью метода опорных векторов, необходимо запрограммировать функцию, реализующую применение ядра Гаусса. Под ядром Гаусса подразумевается функция, определяющая сходство пары образцов на основании оценки расстояния между ними $(х(i), х(j))$. Ядро Гаусса регулируется параметром $σ$, который определяет, насколько быстро уменьшается «схожесть» двух примеров при увеличении расстояния между ними.\n",
        "\n",
        "Необходимую формулу для реализации функции gaussianKernel, Вы найдете в лабнике, в пункте $1.2.1$"
      ],
      "metadata": {
        "id": "4pwOtgwuis5d"
      },
      "id": "4pwOtgwuis5d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7f7defda",
      "metadata": {
        "id": "7f7defda"
      },
      "outputs": [],
      "source": [
        "def gaussianKernel(x1, x2, sigma=0.1):\n",
        "  '''\n",
        "  sim = gaussianKernel(x1, x2) Под ядром Гаусса подразумевается функция,\n",
        "  определяющая сходство пары образцов на основании оценки расстояния между ними.\n",
        "  Возвращаемой величиной является переменная sim\n",
        "\n",
        "  Следует определить векторы x1 и x2 как векторы-столбцы\n",
        "  '''\n",
        "  # ====================== Ваш код здесь ======================\n",
        "  # Указание: Запрограммируйте функцию, табулирующую близость векторов x1 и x2,\n",
        "  # вычисляя значение ядра Гаусса, с параметром sigma\n",
        "\n",
        "\n",
        "  return sim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussianKernelGramMatrix(X1, X2, K_function=gaussianKernel, sigma=0.1):\n",
        "  gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\n",
        "  for i, x1 in enumerate(X1):\n",
        "    for j, x2 in enumerate(X2):\n",
        "      gram_matrix[i, j] = K_function(x1, x2, sigma)\n",
        "  return gram_matrix"
      ],
      "metadata": {
        "id": "W9VK2eSjiSGU"
      },
      "id": "W9VK2eSjiSGU",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как только вы закончите написание программы gaussianKernel.m, ноутбук проверит Вашу функцию нахождения ядра на 2-х представленных примерах, в ответе Вы должны будете увидеть следующее значение: 0.324652"
      ],
      "metadata": {
        "id": "1ypQK4P0iA67"
      },
      "id": "1ypQK4P0iA67"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2b96d893",
      "metadata": {
        "scrolled": true,
        "id": "2b96d893",
        "outputId": "9d23122d-3e2d-47c1-d212-a0f5795bf778",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Kernel between x1 = [1 2 1] , x2 = [ 0  4 -1] , sigma = 2 :\n",
            "0.324652\n"
          ]
        }
      ],
      "source": [
        "x1 = np.array([1, 2, 1])\n",
        "x2 = np.array([0, 4, -1])\n",
        "sigma = 2\n",
        "sim = gaussianKernel(x1, x2, sigma)\n",
        "\n",
        "print(\"Gaussian Kernel between x1 =\", x1, \", x2 =\", x2, \", sigma =\", sigma, \":\\n{:f}\".format(sim))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e589401",
      "metadata": {
        "id": "9e589401"
      },
      "source": [
        "## Часть 4: Визуализация обучающего набора 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93256f4a",
      "metadata": {
        "id": "93256f4a"
      },
      "outputs": [],
      "source": [
        "mat = scipy.io.loadmat('ex3data2.mat')\n",
        "X = mat[\"X\"]\n",
        "y = mat[\"y\"]\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plotData(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d730bd",
      "metadata": {
        "id": "51d730bd"
      },
      "source": [
        "## Часть 5: Обучение SVM с радиальной базисной функцией Гаусса (Набор данных 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используя SVM с ядром Гаусса, построить нелинейную границу раздела, которая наиболее точно подойдет для классификации предоставленного набора данных.\n",
        "\n",
        "Если Вы правильно написали программу расчета ядра Гаусса, ноутбук продолжит обучение алгоритма, используя 2-й набор данных. На графике (рис. 5) изображена граница раздела 2-х областей, найденная с помощью метода опорных векторов с ядром Гаусса.\n"
      ],
      "metadata": {
        "id": "hw0XcepVjkVA"
      },
      "id": "hw0XcepVjkVA"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d75acda5",
      "metadata": {
        "id": "d75acda5"
      },
      "outputs": [],
      "source": [
        "def visualizeBoundary(X, y, model, varargin=0):\n",
        "    x1plot = np.linspace(X[:,0].min(), X[:,0].max(), 100).T\n",
        "    x2plot = np.linspace(X[:,1].min(), X[:,1].max(), 100).T\n",
        "    X1, X2 = np.meshgrid(x1plot, x2plot)\n",
        "    vals = np.zeros(X1.shape)\n",
        "    for i in range(X1.shape[1]):\n",
        "        this_X = np.column_stack((X1[:, i], X2[:, i]))\n",
        "        vals[:, i] = model.predict(gaussianKernelGramMatrix(this_X, X))\n",
        "    plotData(X, y)\n",
        "    plt.contour(X1, X2, vals, colors=\"blue\", levels=[0], linewidth=10, label='Граница классов')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1da4a169",
      "metadata": {
        "id": "1da4a169"
      },
      "outputs": [],
      "source": [
        "C = 1\n",
        "sigma = 0.1\n",
        "\n",
        "model = svmTrain(X, y, C, \"gaussian_rbf\", sigma=sigma)\n",
        "visualizeBoundary(X, y, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8be3d99",
      "metadata": {
        "id": "b8be3d99"
      },
      "source": [
        "## Часть 6: Визуализация обучающего набора 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этой части упражнения Вы усовершенствуете свои навыки по использованию метода опорных векторов с ядром Гаусса для проведения нелинейной классификации данных. Следующая часть ноутбука загрузит и отобразит график с набором данных для этой части упражнения"
      ],
      "metadata": {
        "id": "b-pN0Q-bktkn"
      },
      "id": "b-pN0Q-bktkn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ca80cb",
      "metadata": {
        "id": "30ca80cb"
      },
      "outputs": [],
      "source": [
        "mat = scipy.io.loadmat('ex3data3.mat')\n",
        "X = mat[\"X\"]\n",
        "y = mat[\"y\"]\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plotData(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "16096014",
      "metadata": {
        "id": "16096014"
      },
      "outputs": [],
      "source": [
        "def dataset3Params(X, y, Xval, yval):\n",
        "  '''\n",
        "  DATASET3PARAMS возвращает искомые параметры C и sigma для третьей части\n",
        "  упражнения, в котором требуется определить оптимальные значения (C, sigma)\n",
        "  для эффективного использования SVM с некоторой радиальной базисной функцией\n",
        "  (например, c гауссовским ядром)\n",
        "\n",
        "  Следует запрограммировать функцию, используя метод перекрестной проверки (кросс-валидация).\n",
        "\n",
        "  Указание: Необходимо также рассчитать ошибку для набора данных, выбранных для проверки.\n",
        "            Ошибка определяет долю примеров для перекрестной проверки, классифицированных\n",
        "            неправильно.\n",
        "  '''\n",
        "  values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
        "\n",
        "\n",
        "  return C, sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bbe5a2",
      "metadata": {
        "id": "86bbe5a2"
      },
      "source": [
        "## Часть 7: Обучение SVM с радиальной базисной функцией Гаусса (Набор данных 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1d726b9",
      "metadata": {
        "id": "a1d726b9"
      },
      "outputs": [],
      "source": [
        "Xval = mat[\"Xval\"]\n",
        "yval = mat[\"yval\"]\n",
        "\n",
        "# Задание: Определить оптимальные параметры С и σ, используя метод перекрестной проверки с помощью множества Хval, yval.\n",
        "C, sigma = dataset3Params(X, y, Xval, yval)\n",
        "print(\"Best parameters are C={:.2f}, sigma={:.2f}\".format(C, sigma))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "487ea521",
      "metadata": {
        "id": "487ea521"
      },
      "outputs": [],
      "source": [
        "model = svmTrain(X, y, C, \"gaussian_rbf\", sigma=sigma)\n",
        "visualizeBoundary(X, y, model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}